{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bD-YRHfi1eC"
      },
      "outputs": [],
      "source": [
        "pip install colorama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smH-VyTOumxs"
      },
      "outputs": [],
      "source": [
        "pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nuqrPu2fVRLx"
      },
      "outputs": [],
      "source": [
        "import zipfile #módulo para manipulação de arquivos zipados\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "import numpy as np\n",
        "import requests as req\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from google.colab.patches import cv2_imshow\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.resnet import ResNet152\n",
        "import os, cv2, numpy as np\n",
        "from matplotlib import pyplot as plt #importa bilbioteca para criação de gráficos\n",
        "from sklearn.model_selection import train_test_split\n",
        "from os import listdir\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils.layer_utils import count_params\n",
        "from keras.models import Sequential\n",
        "from keras.layers import InputLayer, BatchNormalization\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "import tensorflow as tf\n",
        "\n",
        "from colorama import init, Fore, Back, Style\n",
        "import tensorflowjs as tfjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44zrnjzbVXuH",
        "outputId": "ff697180-6d5e-4ead-ec5e-95a60e0ef116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Monta Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# Caminho para o arquivo baixado\n",
        "local_zip = '/content/drive/My Drive/AI/IGTI/Bootcamp Deep Learning/Desafio Final/dataset.zip'\n",
        "# Abre arquivo zipado\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# Extrai arquivo zipado para diretório /tmp\n",
        "zip_ref.extractall('/tmp')\n",
        "# Fecha arquivo baixado\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XwribuDgVaKV"
      },
      "outputs": [],
      "source": [
        "base_dir = '/tmp/dataset'\n",
        "mask_dir = os.path.join(base_dir, 'with_mask') # Diretório com imagens de treinamentos de gatos\n",
        "no_mask_dir = os.path.join(base_dir, 'without_mask') # Diretório com imagens de treinamentos de cachorros\n",
        "HEIGHT = 64\n",
        "WIDTH = 64\n",
        "data = {\n",
        "    'filename': [],\n",
        "    'img': [],\n",
        "    'class': []\n",
        "}\n",
        "_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DkghMPULVfjp"
      },
      "outputs": [],
      "source": [
        "def reset_data (h = 64, w = 64):\n",
        "  global HEIGHT\n",
        "  global WIDTH\n",
        "  global data\n",
        "  \n",
        "  data = {\n",
        "      'filename': [],\n",
        "      'img': [],\n",
        "      'class': []\n",
        "  }\n",
        "  HEIGHT = h\n",
        "  WIDTH = w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PF9RjK47Vhs-"
      },
      "outputs": [],
      "source": [
        "# Le um diretorio e joga pro array de dados\n",
        "def read_folder (folder, with_mask):\n",
        "\n",
        "  for fname in listdir(folder):\n",
        "    fpath = os.path.join(folder, fname)\n",
        "    image = cv2.imread(fpath)\n",
        "    image_resized = cv2.resize(image, (HEIGHT, WIDTH))\n",
        "    data['filename'].append(fpath) # caminho do arquivo\n",
        "    data['img'].append(image_resized) # a imagem vai pro X\n",
        "    data['class'].append(with_mask) # a label vai pro Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Us3nt1rMVjDL"
      },
      "outputs": [],
      "source": [
        "def get_model(imgs_shape = (HEIGHT, WIDTH, 3), act = 'relu'):\n",
        "  model = Sequential()\n",
        "\n",
        "  print(imgs_shape)\n",
        "\n",
        "  # camada de entrada\n",
        "  #model.add(InputLayer(input_shape=imgs_shape))\n",
        "\n",
        "  # convolucional 1\n",
        "  model.add(Conv2D(64, (7, 7), activation=act, input_shape=imgs_shape))\n",
        "  # pooling 1\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # convolucional 2\n",
        "  model.add(Conv2D(128, (5, 5), activation=act))\n",
        "  # pooling 2\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # convolucional 3\n",
        "  model.add(Conv2D(256, (5, 5), activation=act))\n",
        "  # pooling 3\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # convolucional 4\n",
        "  model.add(Conv2D(512, (3, 3), activation=act))\n",
        "\n",
        "  # convolucional 5\n",
        "  model.add(Conv2D(1024, (3, 3), activation=act, padding='same'))\n",
        "\n",
        "  # pooling 4\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  #Flattening\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # camada totalmente conectada 1\n",
        "  model.add(Dense(256, activation=act))\n",
        "\n",
        "  # camada totalmente conectada 2\n",
        "  model.add(Dense(256, activation=act))\n",
        "\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  # camada saída\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "T5PJVQyIVoe7"
      },
      "outputs": [],
      "source": [
        "def update_train_test (test_size = 0.30):\n",
        "  # Converte os dados com as novas imgs e labels pra um numpy array\n",
        "  X = np.array(data['img'])\n",
        "  Y = np.array(data['class'])\n",
        "\n",
        "  # train test split\n",
        "  entrada_train, entrada_test, saida_train, saida_test = train_test_split(X, Y, test_size=test_size)\n",
        "\n",
        "  # normalize\n",
        "  entrada_train_norm = entrada_train / 255.0\n",
        "  entrada_test_norm = entrada_test / 255.0\n",
        "  saida_train = to_categorical(saida_train)\n",
        "  saida_test = to_categorical(saida_test)\n",
        "\n",
        "  return entrada_train_norm, entrada_test_norm, entrada_train, entrada_test, saida_train, saida_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Nbdli_pHVpHT"
      },
      "outputs": [],
      "source": [
        "# le os 2 diretórios\n",
        "reset_data()\n",
        "read_folder(mask_dir, 1)\n",
        "read_folder(no_mask_dir, 0)\n",
        "\n",
        "entrada_train_norm, entrada_test_norm, entrada_train, entrada_test, saida_train, saida_test = update_train_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUiPGeilPYqv",
        "outputId": "83d65dd3-d49c-4527-a685-6c4f2f5137ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 64, 3)\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 14s 333ms/step - loss: 0.7325 - accuracy: 0.4870 - val_loss: 0.6909 - val_accuracy: 0.4470\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.6771 - accuracy: 0.5519 - val_loss: 0.6318 - val_accuracy: 0.7576\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5774 - accuracy: 0.6851 - val_loss: 0.6516 - val_accuracy: 0.6591\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5203 - accuracy: 0.8506 - val_loss: 0.7388 - val_accuracy: 0.7424\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4802 - accuracy: 0.8442 - val_loss: 0.3448 - val_accuracy: 0.9091\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2815 - accuracy: 0.9156 - val_loss: 0.6409 - val_accuracy: 0.7955\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2946 - accuracy: 0.9026 - val_loss: 0.4040 - val_accuracy: 0.8485\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2528 - accuracy: 0.9123 - val_loss: 0.3435 - val_accuracy: 0.8864\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1966 - accuracy: 0.9448 - val_loss: 0.3743 - val_accuracy: 0.9015\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2500 - accuracy: 0.9188 - val_loss: 0.3181 - val_accuracy: 0.8485\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.3222 - accuracy: 0.8701 - val_loss: 0.2711 - val_accuracy: 0.9091\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2863 - accuracy: 0.8994 - val_loss: 0.4233 - val_accuracy: 0.8409\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.2139 - accuracy: 0.9253 - val_loss: 0.2538 - val_accuracy: 0.9015\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.2431 - accuracy: 0.9026 - val_loss: 0.2691 - val_accuracy: 0.9015\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1856 - accuracy: 0.9351 - val_loss: 0.5801 - val_accuracy: 0.8409\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.2029 - accuracy: 0.9383 - val_loss: 0.2609 - val_accuracy: 0.9015\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.1430 - accuracy: 0.9513 - val_loss: 0.2756 - val_accuracy: 0.9015\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1532 - accuracy: 0.9545 - val_loss: 0.3096 - val_accuracy: 0.9091\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.1172 - accuracy: 0.9545 - val_loss: 0.4532 - val_accuracy: 0.8712\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1248 - accuracy: 0.9513 - val_loss: 0.3536 - val_accuracy: 0.8939\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1702 - accuracy: 0.9383 - val_loss: 0.5484 - val_accuracy: 0.8106\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1954 - accuracy: 0.9123 - val_loss: 0.3278 - val_accuracy: 0.8788\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1137 - accuracy: 0.9610 - val_loss: 0.3795 - val_accuracy: 0.9015\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1070 - accuracy: 0.9610 - val_loss: 0.2759 - val_accuracy: 0.9091\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0771 - accuracy: 0.9708 - val_loss: 0.5478 - val_accuracy: 0.8485\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0680 - accuracy: 0.9643 - val_loss: 0.5859 - val_accuracy: 0.8939\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0447 - accuracy: 0.9838 - val_loss: 0.7882 - val_accuracy: 0.9015\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0852 - accuracy: 0.9708 - val_loss: 0.5190 - val_accuracy: 0.8939\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0494 - accuracy: 0.9838 - val_loss: 0.5297 - val_accuracy: 0.8864\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.7061 - val_accuracy: 0.8864\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0372 - accuracy: 0.9838 - val_loss: 0.9738 - val_accuracy: 0.8485\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.3455 - accuracy: 0.9091 - val_loss: 0.8703 - val_accuracy: 0.6818\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.3912 - accuracy: 0.8247 - val_loss: 0.5728 - val_accuracy: 0.8864\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2956 - accuracy: 0.8734 - val_loss: 0.4017 - val_accuracy: 0.8636\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.2168 - accuracy: 0.9351 - val_loss: 0.3114 - val_accuracy: 0.8864\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1023 - accuracy: 0.9675 - val_loss: 0.4651 - val_accuracy: 0.9015\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1021 - accuracy: 0.9545 - val_loss: 0.4201 - val_accuracy: 0.8712\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0782 - accuracy: 0.9740 - val_loss: 0.4487 - val_accuracy: 0.8864\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.6316 - val_accuracy: 0.8864\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0313 - accuracy: 0.9838 - val_loss: 0.6628 - val_accuracy: 0.8939\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1129 - accuracy: 0.9578 - val_loss: 0.6112 - val_accuracy: 0.8485\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1242 - accuracy: 0.9643 - val_loss: 0.5542 - val_accuracy: 0.8561\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0450 - accuracy: 0.9870 - val_loss: 0.7250 - val_accuracy: 0.8788\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0158 - accuracy: 0.9935 - val_loss: 0.8185 - val_accuracy: 0.8864\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 1.0368 - val_accuracy: 0.9091\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.0213 - accuracy: 0.9935 - val_loss: 0.9071 - val_accuracy: 0.8939\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.7650 - val_accuracy: 0.8788\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8820 - val_accuracy: 0.8939\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8971 - val_accuracy: 0.8939\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1320 - val_accuracy: 0.8939\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1828171e50>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy'])\n",
        "model.fit(entrada_train_norm, saida_train, validation_data=(entrada_test_norm, saida_test), epochs=_epochs, verbose=1, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvg6Hjx479ov",
        "outputId": "02eb9e4a-48e1-4fa6-bd01-a7c7b71d0d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/AI/IGTI/Bootcamp Deep Learning/Desafio Final/facemask/assets\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/My Drive/AI/IGTI/Bootcamp Deep Learning/Desafio Final/facemask')\n",
        "tfjs.converters.save_keras_model(model, '/content/drive/My Drive/AI/IGTI/Bootcamp Deep Learning/Desafio Final/facemask-tfjs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XrJpOdZxX75X"
      },
      "outputs": [],
      "source": [
        "folder = '/content/drive/My Drive/AI/IGTI/Bootcamp Deep Learning/Desafio Final/pics'\n",
        "reset_data()\n",
        "read_folder(folder, 0)\n",
        "\n",
        "x = np.array(data['img'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "94Qd7LOsZNV-"
      },
      "outputs": [],
      "source": [
        "res = model.predict(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjBi6plbfZEm"
      },
      "outputs": [],
      "source": [
        "t = ['SIM', 'não']\n",
        "\n",
        "c = [Fore.GREEN, Fore.RED]\n",
        "\n",
        "i = 0\n",
        "\n",
        "for r in res:\n",
        "  cv2_imshow(x[i])\n",
        "  ri = int(r[0])\n",
        "  print(c[ri] + t[ri])\n",
        "  print('\\n\\n\\n')\n",
        "  i = i + 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "facemask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}